### 激活函数

+ identify-function恒等函数（输入出等于输入）
+ step-funciton (阶跃) (0,1)
+ sigmoid (可导) (0,1) ：$y = \frac{1}{1 + e^{-x}}$

- sigmoid-grad
- Relu (0,x)
- Relu-grad()
- softmax

> 一般地, 
>
> 回归问题：恒等函数（输入出等于输入） 
>
> 二分类： sigmoid 
>
> 多元分类： softmax()   单调递增函数



###### sigmoid**函数本质**：

+ 用线性回归模型的结果去逼近真实标记的对数几率

优点：

+ 直接对分类可能性进行建模
+ 无需事先假设数据分布，避免了假设分布不准确所带来的问题
+ 不只是预测出类别，而是得到近似概率预测，对许多需要利用概率辅助决策的任务很有帮助
+ 任意阶可导的凸函数，有很好的数学性质
+ 现有的许多数值优化算法都可直接用于求取最优解
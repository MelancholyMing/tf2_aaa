激活函数：

sigmoid

tanh

relu

softmax



分布：

0-1分布

二项分布

泊松分布

均匀分布

指数分布

正态

泰勒公式





> 正规方程： $\theta = (X^TX)^{-1}X^Ty$
>
> 优点：
>
> + 不需要选择学习率 $\alpha$
> + 不需要迭代
>
> 缺点：
>
> + 特征很多时($n \geqslant 10^4)，计算会很慢 （$O(n^3)$）
>
> 梯度下降：
>
> 缺点：
>
> + 需要选择学习率 $\alpha$
> + 需要很多次迭代
>
> 优点：
>
> + 特征n很多的情况依然可以算

 



> 线性回归的代价函数总是凸函数
>
> 凸函数: 没有局部最优解， 局部最优解就是全局最优
>
> 分类问题不用均方误差
>
> 对数似然损失函数：
> $$
> Cost(h_\theta(x),y) = \left\{
> \begin{aligned}
> -\log(h_\theta(x))\qquad&if\;y = 1\\
> -\log(1-h_\theta(x))\quad&if\;y=0
> \end{aligned}
> \right.
> $$
> ——————>$Cost(h_\theta(x), y) = -y\log(h_\theta(x)) - (1-y)\log(1-h_\theta(x))$



